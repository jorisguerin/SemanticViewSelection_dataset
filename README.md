# SemanticViewSelection_dataset

All the images composing the dataset can be downloaded at the following link: https://figshare.com/articles/dataset/Semantic_View_Selection_dataset/13554047

### 1. TITLE: 

Semantic View Selection dataset

### 2. CONTACT: 

[Joris GUERIN](https://jorisguerin.github.io/)  
Laboratoire d'Ingénierie des Systèmes Physiques Et Numériques, Arts et Métiers ParisTech, Lille, France  
Ecole Nationale supérieure des Arts et Métiers  
8 Boulevard Louis XIV  
59800 LILLE  
FRANCE  
email: jorisguerin.research@gmail.com

### 3. RELEVANT INFORMATION:
      
This database was created in the context of our IROS 2018 paper: [Semantically Meaningful View Selection](https://arxiv.org/abs/1807.10303). 
This paper introduces the problem of optimal view selection for semantic understanding. 
The dataset contains around 10k images representing various everyday objects under different poses, and observed under multiple views with a camera mounted on the end-effector of a UR10 robot manipulator.
More details can be found in the paper.

### 4. NUMBER OF INSTANCES:

      29 semantic categories
      144 objects (4 to 6 per category)
      432 poses (3 per object)
      9112 images (17 to 22 per pose)

### 5. NAMING CONVENTION:

The image folder is organized in subfolders which represent, in descending order: classes/objects/poses/views.

### 8. MISSING ATTRIBUTE VALUES: 

      None

### 9. CITATION:

If you find this dataset useful in your research, please consider citing:

      @inproceedings{guerin2018semantically,
  	title        = {Semantically Meaningful View Selection},
  	author       = {Gu{\'e}rin, Joris and Gibaru, Olivier and Nyiri, Eric and Thieryl, Stephane and Boots, Byron},
  	booktitle    = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
 	pages        = {1061--1066},
 	year         = {2018},
  	organization = {IEEE}
	} 
